{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ai4teen_style_transfer.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rky0930/style_transfer_ai4teen/blob/master/ai4teen_style_transfer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jo5PziEC4hWs"
      },
      "source": [
        "# 인공지능으로 예술 작품 만들기\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/rky0930/style_transfer_ai4teen/blob/master/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5%EC%9C%BC%EB%A1%9C_%EC%98%88%EC%88%A0_%EC%9E%91%ED%92%88_%EB%A7%8C%EB%93%A4%EA%B8%B0_%EC%8B%A4%EC%8A%B5%EC%9E%90%EB%A3%8C.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/rky0930/style_transfer_ai4teen/blob/master/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5%EC%9C%BC%EB%A1%9C_%EC%98%88%EC%88%A0_%EC%9E%91%ED%92%88_%EB%A7%8C%EB%93%A4%EA%B8%B0_%EC%8B%A4%EC%8A%B5%EC%9E%90%EB%A3%8C.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aDyGj8DmXCJI"
      },
      "source": [
        "이 튜토리얼은 [Neural Style Transfer with tf.keras](https://colab.research.google.com/github/tensorflow/models/blob/master/research/nst_blogpost/4_Neural_Style_Transfer_with_Eager_Execution.ipynb)를 기반으로 제작 되었습니다.  \n",
        "내용을 한글화하고 인공지능 기술 직접 체험하는 것에 초점을 맞춰 기술적인 자세한 내용은 배제하고 제작하였습니다.\n",
        "\n",
        "## 개요\n",
        "이 튜토리얼에서는 인공지능 분야에서 가장 활발하게 사용되는 딥러닝 기술을 사용하여  두 사진을 합성하는 방법을 배울 것입니다. 두 사진 중 한 사진의 \"컨텐츠\"에 나머지 한 사진의 \"스타일\"을 합성하는 방법입니다.\n",
        "이 합성 기술을 \"Neural Style Transfer\"이라고 합니다. 자세한 설명은 이 논문([Leon A. Gatys' paper, A Neural Algorithm of Artistic Style](https://arxiv.org/abs/1508.06576)) 을 참조하시 기 바랍니다. **단, 이 튜토리얼을 완수하기 위해 논문을 읽을 필요는 없습니다 !**\n",
        "\n",
        "그럼 이제  Neural Style Transfer 에 대해 알아봅시다.\n",
        "\n",
        "Neural Style Transfer는 2장의 사진에서 각각 \"컨텐츠\"와 \"스타일\"을 추출한 후 하나의 사진으로 만드는 기술 입니다.  \n",
        " \n",
        "*   컨텐츠 사진 +  스타일 사진  = 컨텐츠에 스타일이 더해진 사진\n",
        "*   거북이 사진 + 유명 화가의 그림 = 유명 화가의 스타일로 그린 거북이 사진\n",
        "\n",
        "<br>\n",
        "   \n",
        "\n",
        "예를 들어, 아래와 같이 말 사진과 이중섭의 \"흰 소\"사진이 있다면 이 두 사진에 이 기술을 적용해보겠습니다. \n",
        "\n",
        "#### 컨텐츠 - 말 사진 \n",
        "<img src=\"https://github.com/rky0930/style_transfer_ai4teen/blob/master/images/horse.jpg?raw=1\" alt=\"Drawing\" width=\"500\"/>  \n",
        "#### 스타일 - 이중섭 \"흰 소\"\n",
        "<img src=\"https://github.com/rky0930/style_transfer_ai4teen/blob/master/images/leejungseob_white_ox.jpg?raw=1\" alt=\"Drawing\" width=\"500\"/>  \n",
        "\n",
        "\n",
        "#### 이중섭 \"흰 소\" 스타일을 학습하여 \"말\"을 그리면 ..\n",
        "<img src=\"https://github.com/rky0930/style_transfer_ai4teen/blob/master/images/leejungseob_horse.png?raw=1\" alt=\"Drawing\" width=\"500\"/>\n",
        "\n",
        "어떤가요 ? 정말 이중섭 작가가 그린 \"말\" 같나요 ? \n",
        "단 몇 초만에 특정 화가의 화풍으로 그림을 그린다는게 신기하지 않나요 ?    \n",
        "사실, Style Transfer라 불리는 이 기술은 인공지능을 구현하는 방법 중 하나인 인공 신경망(Neural Network) 내부의 특정 부분을 시각화 한 것입니다. 시각화 결과는 내부가 어떻게 동작하는지 간접적으로 보여주기 때문에 합성된 결과물 뿐만아니라 그 의미 또한 재밌는 기술 입니다.   \n",
        "\n",
        "### Style Transfer 진행 순서\n",
        "\n",
        "1. 데이터 시각화\n",
        "2. 기본적인 데이터 가공 \n",
        "3. 인공 신경망 모델 만들기\n",
        "4. Loss 함수 설정\n",
        "5. 딥러닝 모델 훈련\n",
        "6. 결과 확인\n",
        "\n",
        "** 읽으실 분들 ** 이 자료는 기본적인 머신러닝 지식 없이 인공지능 기술을 직접 사용해 볼 수 있도록 제작 되었습니다. 이 자료를 읽은 많은 분들이 인공지능 기술에 흥미를 가지게 되고, 인공지능 관련 공부를 시작하게 되는 계기가 되기를 바랍니다.   \n",
        "더 많은 내용을 알고 싶은 분들은 아래 자료를 참고해 주세요.   \n",
        "* [Neural Style Transfer with tf.keras](#)\n",
        "* [Gatys' paper](https://arxiv.org/abs/1508.06576) \n",
        "* [Understand reducing loss with gradient descent](https://developers.google.com/machine-learning/crash-course/reducing-loss/gradient-descent)\n",
        "\n",
        "**튜토리얼 완수 예상 소요 시간**: 15 분 \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "U8ajP_u73s6m"
      },
      "source": [
        "## 설정하기\n",
        "\n",
        "### 사진 다운로드\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "riWE_b8k3s6o",
        "colab": {}
      },
      "source": [
        "import os\n",
        "img_dir = '/tmp/nst'\n",
        "if not os.path.exists(img_dir):\n",
        "    os.makedirs(img_dir)\n",
        "!wget --quiet -P /tmp/nst/ https://github.com/rky0930/style_transfer_ai4teen/blob/master/images/horse.jpg?raw=1\n",
        "!wget --quiet -P /tmp/nst/ https://github.com/rky0930/style_transfer_ai4teen/blob/master/images/leejungseob_white_ox.jpg?raw=1\n",
        "!wget --quiet -P /tmp/nst/ https://upload.wikimedia.org/wikipedia/commons/d/d7/Green_Sea_Turtle_grazing_seagrass.jpg\n",
        "!wget --quiet -P /tmp/nst/ https://upload.wikimedia.org/wikipedia/commons/0/0a/The_Great_Wave_off_Kanagawa.jpg\n",
        "!wget --quiet -P /tmp/nst/ https://upload.wikimedia.org/wikipedia/commons/b/b4/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg\n",
        "!wget --quiet -P /tmp/nst/ https://upload.wikimedia.org/wikipedia/commons/0/00/Tuebingen_Neckarfront.jpg\n",
        "!wget --quiet -P /tmp/nst/ https://upload.wikimedia.org/wikipedia/commons/6/68/Pillars_of_creation_2014_HST_WFC3-UVIS_full-res_denoised.jpg\n",
        "!wget --quiet -P /tmp/nst/ https://upload.wikimedia.org/wikipedia/commons/thumb/e/ea/Van_Gogh_-_Starry_Night_-_Google_Art_Project.jpg/1024px-Van_Gogh_-_Starry_Night_-_Google_Art_Project.jpg\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eqxUicSPUOP6"
      },
      "source": [
        "### 모듈 가져온후 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sc1OLbOWhPCO",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "mpl.rcParams['figure.figsize'] = (10,10)\n",
        "mpl.rcParams['axes.grid'] = False\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import time\n",
        "import functools\n",
        "import tensorflow as tf\n",
        "import tensorflow.contrib.eager as tfe\n",
        "from tensorflow.python.keras.preprocessing import image as kp_image\n",
        "from tensorflow.python.keras import models \n",
        "from tensorflow.python.keras import losses\n",
        "from tensorflow.python.keras import layers\n",
        "from tensorflow.python.keras import backend as K\n",
        "tf.__version__\n",
        "tf.enable_eager_execution()\n",
        "print(\"Eager execution: {}\".format(tf.executing_eagerly()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xE4Yt8nArTeR"
      },
      "source": [
        "## 1. 데이터 시각화 - 입력 사진 시각화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-b9WcWqy4JWu",
        "colab": {}
      },
      "source": [
        "# Set up some global values here\n",
        "content_path = '/tmp/nst/horse.jpg?raw=1'\n",
        "style_path = '/tmp/nst/leejungseob_white_ox.jpg?raw=1'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3TLljcwv5qZs",
        "colab": {}
      },
      "source": [
        "def load_img(path_to_img):\n",
        "  max_dim = 512\n",
        "  img = Image.open(path_to_img)\n",
        "  long = max(img.size)\n",
        "  scale = max_dim/long\n",
        "  img = img.resize((round(img.size[0]*scale), round(img.size[1]*scale)), Image.ANTIALIAS)\n",
        "  \n",
        "  img = kp_image.img_to_array(img)\n",
        "  \n",
        "  # We need to broadcast the image array such that it has a batch dimension \n",
        "  img = np.expand_dims(img, axis=0)\n",
        "  return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vupl0CI18aAG",
        "colab": {}
      },
      "source": [
        "def imshow(img, title=None):\n",
        "  # Remove the batch dimension\n",
        "  out = np.squeeze(img, axis=0)\n",
        "  # Normalize for display \n",
        "  out = out.astype('uint8')\n",
        "  plt.imshow(out)\n",
        "  if title is not None:\n",
        "    plt.title(title)\n",
        "  plt.imshow(out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2yAlRzJZrWM3"
      },
      "source": [
        "컨텐츠 사진과 스타일 사진 확인하기.  \n",
        "우리가 원하는 결과는 컨텐츠 사진의 형태는 유지하면서 스타일 사진의 스타일을 더하는 것 입니다 !"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_UWQmeEaiKkP",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "\n",
        "content = load_img(content_path).astype('uint8')\n",
        "style = load_img(style_path).astype('uint8')\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "imshow(content, 'Content Image')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "imshow(style, 'Style Image')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7qMVNvEsK-_D"
      },
      "source": [
        "## 2. 기본적인 데이터 가공\n",
        "### 데이터 전처리 & 후처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hGwmTwJNmv2a",
        "colab": {}
      },
      "source": [
        "def load_and_process_img(path_to_img):\n",
        "  img = load_img(path_to_img)\n",
        "  img = tf.keras.applications.vgg19.preprocess_input(img)\n",
        "  return img\n",
        "\n",
        "def deprocess_img(processed_img):\n",
        "  x = processed_img.copy()\n",
        "  if len(x.shape) == 4:\n",
        "    x = np.squeeze(x, 0)\n",
        "  assert len(x.shape) == 3, (\"Input to deprocess image must be an image of \"\n",
        "                             \"dimension [1, height, width, channel] or [height, width, channel]\")\n",
        "  if len(x.shape) != 3:\n",
        "    raise ValueError(\"Invalid input to deprocessing image\")\n",
        "  \n",
        "  # perform the inverse of the preprocessiing step\n",
        "  x[:, :, 0] += 103.939\n",
        "  x[:, :, 1] += 116.779\n",
        "  x[:, :, 2] += 123.68\n",
        "  x = x[:, :, ::-1]\n",
        "\n",
        "  x = np.clip(x, 0, 255).astype('uint8')\n",
        "  return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GEwZ7FlwrjoZ"
      },
      "source": [
        "\n",
        "### 사진에서 컨텐츠와 스타일 얻는 방법\n",
        "우리는 사진에서 \"컨텐츠\"와 \"스타일\"을 얻기위해서 딥러닝 모델을 사용할 것 입니다. 우리가 사용할 딥러닝 모델은 여러층으로 이루어져 있는데, 뒤쪽에 위치한 깊은 층일 수록 입력한 사진의 고차원 적인 특징이 추출되고, 앞쪽의 앝은층 일수록 단순한 특징이 추출되는 특성이 있습니다. 이 튜토리얼에서 사용할 딥러닝 모델의 이름은 VGG19 입니다. 원래는 사진 분류기에 사용하기 위해 학습 되었지만 입력된 사진의 \"컨텐츠\"와 \"스타일\"을 추출 할 때도 사용 할 수 있습니다.\n",
        "\n",
        "#### 사진 분류기용 신경망으로 \"컨텐츠\"와 \"스타일\"을 추출 ?\n",
        "어떻게 사진 분류기용 딥러닝 모델을 사용하여 \"컨텐츠\" 와 \"스타일\"을 추출 하는지 궁금하신가요? 우선, 우리가 사용하는 사진 분류기용 딥러닝 모델이 어떻게 동작하는지 설명해야 합니다. 사진 분류기에서 사용되는 딥러닝 모델은 사진을 픽셀 단위로 입력 받아 딥러닝 내부적인 표현 방식으로 변환하여 입력 받은 사진에 존재하는 복잡한 특징을 자체적으로 이해합니다. 특정 사물의 사진들에 공통적으로 존재하는 특징 찾는다면, 이 특징들을 사용하여 사진 분류기로 동작 시킬 수 있습니다. 예를들어, 강아지 사진에만 존재하는 특징을 찾고, 고양이 사진에만 존재하는 특징을 찾는다면 강아지 사진과 고양이 사진을 분류할 수 있는 사진 분류기를 만들 수 있겠죠 ! 이게 바로 딥러닝 기술의 마법 같은 능력입니다. 딥러닝을 사용하여 사진에 존재하는 특징을 추출 하고 이 특징들을 사진 분류기에 사용하는 것 입니다. 그럼 Style Transfer는 어떻게 동작할까요 ? 사진의 \"컨텐츠\"와 \"스타일\" 또한 사진의 특징 중 하나 입니다. 다만,  Style Transfer에서는 사진을 분류하는데 사용하지 않고 추출한 두 특징을 하나의 사진으로 합성하여 새로운 사진을 만들어 내는 것 입니다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Jt3i3RRrJiOX"
      },
      "source": [
        "## 4. 인공 신경망 모델 만들기 - 딥러닝 모델 만들기\n",
        "앞서 말씀드린 듯이 우리는 [VGG19](https://keras.io/applications/#vgg19)를 사용할 것 입니다. 이 모델은 원래 논문에서 제시되었기도 하고 비교적 간단하면서도  높은 성능을 보여줍니다. 이제 이 모델을 사용하여 사진의 \"컨텐츠\"와 \"스타일\"을 추출하여 합성된 이미지를 만들 것입니다. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nfec6MuMAbPx",
        "colab": {}
      },
      "source": [
        "# Content layer where will pull our feature maps\n",
        "content_layers = ['block5_conv2'] \n",
        "\n",
        "# Style layer we are interested in\n",
        "style_layers = ['block1_conv1',\n",
        "                'block2_conv1',\n",
        "                'block3_conv1', \n",
        "                'block4_conv1', \n",
        "                'block5_conv1'\n",
        "               ]\n",
        "\n",
        "num_content_layers = len(content_layers)\n",
        "num_style_layers = len(style_layers)\n",
        "\n",
        "def get_model():\n",
        "  \"\"\" Creates our model with access to intermediate layers. \n",
        "  \n",
        "  This function will load the VGG19 model and access the intermediate layers. \n",
        "  These layers will then be used to create a new model that will take input image\n",
        "  and return the outputs from these intermediate layers from the VGG model. \n",
        "  \n",
        "  Returns:\n",
        "    returns a keras model that takes image inputs and outputs the style and \n",
        "      content intermediate layers. \n",
        "  \"\"\"\n",
        "  # Load our model. We load pretrained VGG, trained on imagenet data\n",
        "  vgg = tf.keras.applications.vgg19.VGG19(include_top=False, weights='imagenet')\n",
        "  vgg.trainable = False\n",
        "  # Get output layers corresponding to style and content layers \n",
        "  style_outputs = [vgg.get_layer(name).output for name in style_layers]\n",
        "  content_outputs = [vgg.get_layer(name).output for name in content_layers]\n",
        "  model_outputs = style_outputs + content_outputs\n",
        "  # Build model \n",
        "  return models.Model(vgg.input, model_outputs)\n",
        "\n",
        "def get_feature_representations(model, content_path, style_path):\n",
        "  \"\"\"Helper function to compute our content and style feature representations.\n",
        "\n",
        "  This function will simply load and preprocess both the content and style \n",
        "  images from their path. Then it will feed them through the network to obtain\n",
        "  the outputs of the intermediate layers. \n",
        "  \n",
        "  Arguments:\n",
        "    model: The model that we are using.\n",
        "    content_path: The path to the content image.\n",
        "    style_path: The path to the style image\n",
        "    \n",
        "  Returns:\n",
        "    returns the style features and the content features. \n",
        "  \"\"\"\n",
        "  # Load our images in \n",
        "  content_image = load_and_process_img(content_path)\n",
        "  style_image = load_and_process_img(style_path)\n",
        "  \n",
        "  # batch compute content and style features\n",
        "  style_outputs = model(style_image)\n",
        "  content_outputs = model(content_image)\n",
        "  \n",
        "  \n",
        "  # Get the style and content feature representations from our model  \n",
        "  style_features = [style_layer[0] for style_layer in style_outputs[:num_style_layers]]\n",
        "  content_features = [content_layer[0] for content_layer in content_outputs[num_style_layers:]]\n",
        "  return style_features, content_features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kl6eFGa7-OtV"
      },
      "source": [
        "방금 우리는 위 소스코드를 실행하여 학습이 완료된 사진분류기용 딥러닝 모델을 로딩했습니다. 그리고, 우리가 사용할 \"컨텐츠\"와 \"스타일\" 특징이 저장되어 있는 층을 지정하고 특징 추출에 사용할 함수를 정의하였습니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ezVR67gTt-FW"
      },
      "source": [
        "## 5. Loss 함수 설정 - Loss 함수와 경사 하강법\n",
        "이 글을 읽는 초심자들에게 Loss함수, 경사하강법과 역전파 등은 익숙한 개념이 아닐 수 있습니다. 이것들은 딥러닝 모델을 학습시키기 위해 필수적인 아주 중요한 요소입니다. 다만, 이 내용은 수학적 배경이 필요하기 때문에 이 튜토리얼에서는 제외하였습니다. 이 튜토리얼을 실행하기위해 당장 이것들을 이해할 필요는 없습니다. 자세한 내용이 궁금하신 분들은 튜토리얼 초반에 언급한 자료를 확인해 주세요.   \n",
        "아래의 코드를 실행하면  Loss 함수와 경사하강에 관련된 필요한 파이썬 함수들이 정의 됩니다. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d2mf7JwRMkCd",
        "colab": {}
      },
      "source": [
        "def get_content_loss(base_content, target):\n",
        "  return tf.reduce_mean(tf.square(base_content - target))\n",
        "\n",
        "def gram_matrix(input_tensor):\n",
        "  # We make the image channels first \n",
        "  channels = int(input_tensor.shape[-1])\n",
        "  a = tf.reshape(input_tensor, [-1, channels])\n",
        "  n = tf.shape(a)[0]\n",
        "  gram = tf.matmul(a, a, transpose_a=True)\n",
        "  return gram / tf.cast(n, tf.float32)\n",
        "\n",
        "def get_style_loss(base_style, gram_target):\n",
        "  \"\"\"Expects two images of dimension h, w, c\"\"\"\n",
        "  # height, width, num filters of each layer\n",
        "  # We scale the loss at a given layer by the size of the feature map and the number of filters\n",
        "  height, width, channels = base_style.get_shape().as_list()\n",
        "  gram_style = gram_matrix(base_style)\n",
        "  \n",
        "  return tf.reduce_mean(tf.square(gram_style - gram_target))# / (4. * (channels ** 2) * (width * height) ** 2)\n",
        "\n",
        "def compute_loss(model, loss_weights, init_image, gram_style_features, content_features):\n",
        "  \"\"\"This function will compute the loss total loss.\n",
        "  \n",
        "  Arguments:\n",
        "    model: The model that will give us access to the intermediate layers\n",
        "    loss_weights: The weights of each contribution of each loss function. \n",
        "      (style weight, content weight, and total variation weight)\n",
        "    init_image: Our initial base image. This image is what we are updating with \n",
        "      our optimization process. We apply the gradients wrt the loss we are \n",
        "      calculating to this image.\n",
        "    gram_style_features: Precomputed gram matrices corresponding to the \n",
        "      defined style layers of interest.\n",
        "    content_features: Precomputed outputs from defined content layers of \n",
        "      interest.\n",
        "      \n",
        "  Returns:\n",
        "    returns the total loss, style loss, content loss, and total variational loss\n",
        "  \"\"\"\n",
        "  style_weight, content_weight = loss_weights\n",
        "  \n",
        "  # Feed our init image through our model. This will give us the content and \n",
        "  # style representations at our desired layers. Since we're using eager\n",
        "  # our model is callable just like any other function!\n",
        "  model_outputs = model(init_image)\n",
        "  \n",
        "  style_output_features = model_outputs[:num_style_layers]\n",
        "  content_output_features = model_outputs[num_style_layers:]\n",
        "  \n",
        "  style_score = 0\n",
        "  content_score = 0\n",
        "\n",
        "  # Accumulate style losses from all layers\n",
        "  # Here, we equally weight each contribution of each loss layer\n",
        "  weight_per_style_layer = 1.0 / float(num_style_layers)\n",
        "  for target_style, comb_style in zip(gram_style_features, style_output_features):\n",
        "    style_score += weight_per_style_layer * get_style_loss(comb_style[0], target_style)\n",
        "    \n",
        "  # Accumulate content losses from all layers \n",
        "  weight_per_content_layer = 1.0 / float(num_content_layers)\n",
        "  for target_content, comb_content in zip(content_features, content_output_features):\n",
        "    content_score += weight_per_content_layer* get_content_loss(comb_content[0], target_content)\n",
        "  \n",
        "  style_score *= style_weight\n",
        "  content_score *= content_weight\n",
        "\n",
        "  # Get total loss\n",
        "  loss = style_score + content_score \n",
        "  return loss, style_score, content_score\n",
        "\n",
        "def compute_grads(cfg):\n",
        "  with tf.GradientTape() as tape: \n",
        "    all_loss = compute_loss(**cfg)\n",
        "  # Compute gradients wrt input image\n",
        "  total_loss = all_loss[0]\n",
        "  return tape.gradient(total_loss, cfg['init_image']), all_loss\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pXIUX6czZABh"
      },
      "source": [
        "## 5. 딥러닝 모델 훈련 - 입력 사진에 Style Transfer 적용하기\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "T9yKu2PLlBIE"
      },
      "source": [
        "### 딥러닝 훈련 함수 정의\n",
        "아래의 소스코드를 실행하면 딥러닝 모델을 훈련하기위한 파이썬 함수가 정의 됩니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pj_enNo6tACQ",
        "colab": {}
      },
      "source": [
        "import IPython.display\n",
        "\n",
        "def run_style_transfer(content_path, \n",
        "                       style_path,\n",
        "                       num_iterations=1000,\n",
        "                       content_weight=1e3, \n",
        "                       style_weight=1e-2): \n",
        "  # We don't need to (or want to) train any layers of our model, so we set their\n",
        "  # trainable to false. \n",
        "  model = get_model() \n",
        "  for layer in model.layers:\n",
        "    layer.trainable = False\n",
        "  \n",
        "  # Get the style and content feature representations (from our specified intermediate layers) \n",
        "  style_features, content_features = get_feature_representations(model, content_path, style_path)\n",
        "  gram_style_features = [gram_matrix(style_feature) for style_feature in style_features]\n",
        "  \n",
        "  # Set initial image\n",
        "  init_image = load_and_process_img(content_path)\n",
        "  init_image = tfe.Variable(init_image, dtype=tf.float32)\n",
        "  # Create our optimizer\n",
        "  opt = tf.train.AdamOptimizer(learning_rate=5, beta1=0.99, epsilon=1e-1)\n",
        "\n",
        "  # For displaying intermediate images \n",
        "  iter_count = 1\n",
        "  \n",
        "  # Store our best result\n",
        "  best_loss, best_img = float('inf'), None\n",
        "  \n",
        "  # Create a nice config \n",
        "  loss_weights = (style_weight, content_weight)\n",
        "  cfg = {\n",
        "      'model': model,\n",
        "      'loss_weights': loss_weights,\n",
        "      'init_image': init_image,\n",
        "      'gram_style_features': gram_style_features,\n",
        "      'content_features': content_features\n",
        "  }\n",
        "    \n",
        "  # For displaying\n",
        "  num_rows = 2\n",
        "  num_cols = 5\n",
        "  display_interval = num_iterations/(num_rows*num_cols)\n",
        "  start_time = time.time()\n",
        "  global_start = time.time()\n",
        "  \n",
        "  norm_means = np.array([103.939, 116.779, 123.68])\n",
        "  min_vals = -norm_means\n",
        "  max_vals = 255 - norm_means   \n",
        "  \n",
        "  imgs = []\n",
        "  for i in range(num_iterations):\n",
        "    grads, all_loss = compute_grads(cfg)\n",
        "    loss, style_score, content_score = all_loss\n",
        "    opt.apply_gradients([(grads, init_image)])\n",
        "    clipped = tf.clip_by_value(init_image, min_vals, max_vals)\n",
        "    init_image.assign(clipped)\n",
        "    end_time = time.time() \n",
        "    \n",
        "    if loss < best_loss:\n",
        "      # Update best loss and best image from total loss. \n",
        "      best_loss = loss\n",
        "      best_img = deprocess_img(init_image.numpy())\n",
        "\n",
        "    if i % display_interval== 0:\n",
        "      start_time = time.time()\n",
        "      \n",
        "      # Use the .numpy() method to get the concrete numpy array\n",
        "      plot_img = init_image.numpy()\n",
        "      plot_img = deprocess_img(plot_img)\n",
        "      imgs.append(plot_img)\n",
        "      IPython.display.clear_output(wait=True)\n",
        "      IPython.display.display_png(Image.fromarray(plot_img))\n",
        "      print('Iteration: {}'.format(i))        \n",
        "      print('Total loss: {:.4e}, ' \n",
        "            'style loss: {:.4e}, '\n",
        "            'content loss: {:.4e}, '\n",
        "            'time: {:.4f}s'.format(loss, style_score, content_score, time.time() - start_time))\n",
        "  print('Total time: {:.4f}s'.format(time.time() - global_start))\n",
        "  IPython.display.clear_output(wait=True)\n",
        "  plt.figure(figsize=(14,4))\n",
        "  for i,img in enumerate(imgs):\n",
        "      plt.subplot(num_rows,num_cols,i+1)\n",
        "      plt.imshow(img)\n",
        "      plt.xticks([])\n",
        "      plt.yticks([])\n",
        "      \n",
        "  return best_img, best_loss "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rxJPG_GLUFT9"
      },
      "source": [
        "### 딥러닝 훈련 함수 실행\n",
        "아래의 소스코드를 실행하면 딥러닝 모델의 훈련이 시작 됩니다. 약 5분정도 소요 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vSVMx4burydi",
        "colab": {}
      },
      "source": [
        "best, best_loss = run_style_transfer(content_path, \n",
        "                                     style_path, num_iterations=1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9fegq87PUnCl"
      },
      "source": [
        "#### 결과 확인하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dzJTObpsO3TZ",
        "colab": {}
      },
      "source": [
        "Image.fromarray(best)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LwiZfCW0AZwt"
      },
      "source": [
        "## 6. 결과물 확인하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lqTQN1PjulV9",
        "colab": {}
      },
      "source": [
        "def show_results(best_img, content_path, style_path, show_large_final=True):\n",
        "  plt.figure(figsize=(10, 5))\n",
        "  content = load_img(content_path) \n",
        "  style = load_img(style_path)\n",
        "\n",
        "  plt.subplot(1, 2, 1)\n",
        "  imshow(content, 'Content Image')\n",
        "\n",
        "  plt.subplot(1, 2, 2)\n",
        "  imshow(style, 'Style Image')\n",
        "\n",
        "  if show_large_final: \n",
        "    plt.figure(figsize=(10, 10))\n",
        "\n",
        "    plt.imshow(best_img)\n",
        "    plt.title('Output Image')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "i6d6O50Yvs6a",
        "colab": {}
      },
      "source": [
        "show_results(best, content_path, style_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tyGMmWh2Pss8"
      },
      "source": [
        "## 다른 사진 변환해 보기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "x2TePU39k9lb"
      },
      "source": [
        "### 반고흐 - 별이 빛나는 밤 + 독일 도시 (튀빙겐)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ES9dC6ZyJBD2",
        "colab": {}
      },
      "source": [
        "best_starry_night, best_loss = run_style_transfer('/tmp/nst/Tuebingen_Neckarfront.jpg',\n",
        "                                                  '/tmp/nst/1024px-Van_Gogh_-_Starry_Night_-_Google_Art_Project.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "X8w8WLkKvzXu",
        "colab": {}
      },
      "source": [
        "show_results(best_starry_night, '/tmp/nst/Tuebingen_Neckarfront.jpg',\n",
        "             '/tmp/nst/1024px-Van_Gogh_-_Starry_Night_-_Google_Art_Project.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QcXwvViek4Br"
      },
      "source": [
        "### 창조의 기둥 +  독일 도시 (튀빙겐)\n",
        "창조의 기둥이란 허블 우주망원경이 지구로부터 약 7,000 광년 떨어진 독수리 성운의 성간가스와 성간먼지의 덩어리를 촬영한 사진"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vJ3u2U-gGmgP",
        "colab": {}
      },
      "source": [
        "best_poc_tubingen, best_loss = run_style_transfer('/tmp/nst/Tuebingen_Neckarfront.jpg', \n",
        "                                                  '/tmp/nst/Pillars_of_creation_2014_HST_WFC3-UVIS_full-res_denoised.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pQUq3KxpGv2O",
        "colab": {}
      },
      "source": [
        "show_results(best_poc_tubingen, \n",
        "             '/tmp/nst/Tuebingen_Neckarfront.jpg',\n",
        "             '/tmp/nst/Pillars_of_creation_2014_HST_WFC3-UVIS_full-res_denoised.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bTZdTOdW3s8H"
      },
      "source": [
        "### 구성VII + 독일 도시 (튀빙겐)\n",
        "구성VII: 바실리 칸딘스키의 그림"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bt9mbQfl7exl",
        "colab": {}
      },
      "source": [
        "best_kandinsky_tubingen, best_loss = run_style_transfer('/tmp/nst/Tuebingen_Neckarfront.jpg', \n",
        "                                                  '/tmp/nst/Vassily_Kandinsky,_1913_-_Composition_7.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Qnz8HeXSXg6P",
        "colab": {}
      },
      "source": [
        "show_results(best_kandinsky_tubingen, \n",
        "             '/tmp/nst/Tuebingen_Neckarfront.jpg',\n",
        "             '/tmp/nst/Vassily_Kandinsky,_1913_-_Composition_7.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cg68lW2A3s8N"
      },
      "source": [
        "### 창조의 기둥 + 바다 거북\n",
        "창조의 기둥이란 허블 우주망원경이 지구로부터 약 7,000 광년 떨어진 독수리 성운의 성간가스와 성간먼지의 덩어리를 촬영한 사진\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dl0DUot_bFST",
        "colab": {}
      },
      "source": [
        "best_poc_turtle, best_loss = run_style_transfer('/tmp/nst/Green_Sea_Turtle_grazing_seagrass.jpg', \n",
        "                                                  '/tmp/nst/Pillars_of_creation_2014_HST_WFC3-UVIS_full-res_denoised.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UzJfE0I1bQn8",
        "colab": {}
      },
      "source": [
        "show_results(best_poc_turtle, \n",
        "             '/tmp/nst/Green_Sea_Turtle_grazing_seagrass.jpg',\n",
        "             '/tmp/nst/Pillars_of_creation_2014_HST_WFC3-UVIS_full-res_denoised.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OWPyDfWjZviq"
      },
      "source": [
        "## 사진 직접 올려서 변환해 보기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "S0BWSq7WeZB3"
      },
      "source": [
        "#### 스타일 사진 올리기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XYT4c9BZZvBl",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "print(\"Please Upload Style Image\")\n",
        "my_style_image = files.upload()\n",
        "my_style_image_name =list(my_style_image.keys())[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NBUCt4DKedjY"
      },
      "source": [
        "#### 컨텐츠 사진 올리기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Aqf2B01XYhuR",
        "colab": {}
      },
      "source": [
        "print(\"Please Upload Contents Image\")\n",
        "my_contents_image = files.upload()\n",
        "my_contents_image_name =list(my_contents_image.keys())[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ypdiHyHVbHq4",
        "colab": {}
      },
      "source": [
        "best_image, best_loss = run_style_transfer(my_contents_image_name, my_style_image_name)\n",
        "Image.fromarray(best_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7gBG9MZxbDRo",
        "colab": {}
      },
      "source": [
        "show_results(best_image, my_contents_image_name, my_style_image_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "U-y02GWonqnD"
      },
      "source": [
        "#### 사진 정보 \n",
        "\n",
        "**[Image of Tuebingen](https://commons.wikimedia.org/wiki/File:Tuebingen_Neckarfront.jpg)** \n",
        "Photo By: Andreas Praefcke [GFDL (http://www.gnu.org/copyleft/fdl.html) or CC BY 3.0  (https://creativecommons.org/licenses/by/3.0)], from Wikimedia Commons\n",
        "\n",
        "**[Image of Green Sea Turtle](https://commons.wikimedia.org/wiki/File:Green_Sea_Turtle_grazing_seagrass.jpg)**\n",
        "By P.Lindgren [CC BY-SA 3.0 (https://creativecommons.org/licenses/by-sa/3.0)], from Wikimedia Commons\n",
        "\n",
        "**[Image of White OX](https://ko.wikipedia.org/wiki/%ED%9D%B0_%EC%86%8C)**\n",
        "By 이중섭 from Wikemeia Commons"
      ]
    }
  ]
}