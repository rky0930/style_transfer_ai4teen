{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "인공지능으로 예술 작품 만들기 실습자료",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rky0930/style_transfer_ai4teen/blob/master/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5%EC%9C%BC%EB%A1%9C_%EC%98%88%EC%88%A0_%EC%9E%91%ED%92%88_%EB%A7%8C%EB%93%A4%EA%B8%B0_%EC%8B%A4%EC%8A%B5%EC%9E%90%EB%A3%8C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jo5PziEC4hWs",
        "colab_type": "text"
      },
      "source": [
        "# 인공지능으로 예술 작품 만들기\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/models/blob/master/research/nst_blogpost/4_Neural_Style_Transfer_with_Eager_Execution.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/models/blob/master/research/nst_blogpost/4_Neural_Style_Transfer_with_Eager_Execution.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDyGj8DmXCJI",
        "colab_type": "text"
      },
      "source": [
        "이 튜토리얼은 [Neural Style Transfer with tf.keras](#)을 기반으로 제작 되었습니다.  \n",
        "내용을 한글화하고 인공지능 기술 직접 체험하는 것에 초점을 맞춰 기술적인 자세한 내용은 배제하고 제작하였습니다.\n",
        "\n",
        "## 개요\n",
        "이 튜토리얼에서는 인공지능 분야에서 가장 활발하게 사용되는 딥러닝 기술을 사용하여  두 사진의 \"컨텐츠\"와 \"스타일\"을 합성하는 방법을 배울 것 입니다.\n",
        "이 기술은 \"Neural Style Transfer\" 불립니다. 자세한 설명은 이 논문([Leon A. Gatys' paper, A Neural Algorithm of Artistic Style](https://arxiv.org/abs/1508.06576)) 을 참조하시 기 바랍니다. **단, 이 튜토리얼을 완수하기 위해 논문을 읽을 필요는 없습니다 !**\n",
        "\n",
        "그래서,  Neural Style Transfer 란 무엇일까요 ?\n",
        "\n",
        "Neural Style Transfer는 2장의 사진에서 각각 \"컨텐츠\"와 \"스타일\"을 추출한 후 하나의 사진으로 만드는 기술 입니다.  \n",
        " = 컨텐츠 사진 +  스타일 사진  = 컨텐츠 + 스타일 사진  \n",
        " = 거북이 사진 + 유명 화가의 그림 = 유명 화가의 스타일로 그린 거북이 사진    \n",
        "\n",
        "예를들어, 아래 두 사진을 보겠습니다. \n",
        "\n",
        "<img src=\"https://github.com/rky0930/style_transfer_ai4teen/blob/master/images/gwanghwamun.jpg?raw=1\" alt=\"Drawing\" style=\"width: 200px;\"/>  \n",
        "광화문 *출처 한국관광공사 홈페이지([광화문](http://tong.visitkorea.or.kr/cms/resource/84/2526484_image2_1.jpg))\n",
        "  \n",
        "<img src=\"https://github.com/rky0930/style_transfer_ai4teen/blob/master/images/leejungseob_white_ox.jpg?raw=1\" alt=\"Drawing\" style=\"width: 200px;\"/>  \n",
        "이중섭 - 흰 소\n",
        "\n",
        "이제 이중섭 그림 흰 소의 스타일을 학습하여 \"광화문\"을 그리면..  \n",
        "<img src=\"https://github.com/rky0930/style_transfer_ai4teen/blob/master/images/leejungseob_gwangwhamoon.png?raw=1\" alt=\"Drawing\" style=\"width: 200px;\"/>\n",
        "\n",
        "어떤가요 ? 정말 이중섭 작가가 광화문 그림 같나요 ? 마법같나요 ? 어떤한 마법도 사용하지 않았습니다. 사실, Style Transfer 기술은 인공지능을 만들때 사용되는 인공 신경망(Neural Network) 내부의 특정 부분을 시각화 한 것입니다. 시각화 결과는 내부가 어떻게 동작하는지 간접적으로 보여주기 때문에 합성된 결과물 뿐만아니라 그 의미 또한 재밌는 기술 입니다.   \n",
        "\n",
        "### Style Transfer 진행 순서\n",
        "\n",
        "1. 데이터 시각화\n",
        "2. 기본적인 데이터 가공 \n",
        "3. 인공 신경망 모델 만들기\n",
        "4. Loss 함수 설정\n",
        "5. 딥러닝 모델 훈련\n",
        "6. 결과 확인\n",
        "\n",
        "** 읽으실 분들 ** 이 자료는 기본적인 머신러닝 지식 없이 인공지능 기술을 직접 사용해 볼 수 있도록 제작 되었습니다. 이 자료를 읽은 많은 분들이 인공지능 기술에 흥미를 가지게 되고, 인공지능 관련 공부를 시작하게 되는 계기가 되기를 바랍니다.   \n",
        "더 많은 내용을 알고 싶은 분들은 아래 자료를 참고해 주세요.   \n",
        "* [Neural Style Transfer with tf.keras](#)\n",
        "* [Gatys' paper](https://arxiv.org/abs/1508.06576) \n",
        "* [Understand reducing loss with gradient descent](https://developers.google.com/machine-learning/crash-course/reducing-loss/gradient-descent)\n",
        "\n",
        "**튜토리얼 완수 예상 소요 시간**: 15 분 \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8ajP_u73s6m",
        "colab_type": "text"
      },
      "source": [
        "## 설정하기\n",
        "\n",
        "### 사진 다운로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riWE_b8k3s6o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "img_dir = '/tmp/nst'\n",
        "if not os.path.exists(img_dir):\n",
        "    os.makedirs(img_dir)\n",
        "!wget --quiet -P /tmp/nst/ https://github.com/rky0930/style_transfer_ai4teen/blob/master/images/gwanghwamun.jpg?raw=1\n",
        "!wget --quiet -P /tmp/nst/ https://github.com/rky0930/style_transfer_ai4teen/blob/master/images/leejungseob_white_ox.jpg?raw=1\n",
        "!wget --quiet -P /tmp/nst/ https://upload.wikimedia.org/wikipedia/commons/d/d7/Green_Sea_Turtle_grazing_seagrass.jpg\n",
        "!wget --quiet -P /tmp/nst/ https://upload.wikimedia.org/wikipedia/commons/0/0a/The_Great_Wave_off_Kanagawa.jpg\n",
        "!wget --quiet -P /tmp/nst/ https://upload.wikimedia.org/wikipedia/commons/b/b4/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg\n",
        "!wget --quiet -P /tmp/nst/ https://upload.wikimedia.org/wikipedia/commons/0/00/Tuebingen_Neckarfront.jpg\n",
        "!wget --quiet -P /tmp/nst/ https://upload.wikimedia.org/wikipedia/commons/6/68/Pillars_of_creation_2014_HST_WFC3-UVIS_full-res_denoised.jpg\n",
        "!wget --quiet -P /tmp/nst/ https://upload.wikimedia.org/wikipedia/commons/thumb/e/ea/Van_Gogh_-_Starry_Night_-_Google_Art_Project.jpg/1024px-Van_Gogh_-_Starry_Night_-_Google_Art_Project.jpg\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJiUQtDCe3hs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls /tmp/nst/*"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqxUicSPUOP6",
        "colab_type": "text"
      },
      "source": [
        "### 모듈 가져온후 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sc1OLbOWhPCO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "mpl.rcParams['figure.figsize'] = (10,10)\n",
        "mpl.rcParams['axes.grid'] = False\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import time\n",
        "import functools\n",
        "import tensorflow as tf\n",
        "import tensorflow.contrib.eager as tfe\n",
        "from tensorflow.python.keras.preprocessing import image as kp_image\n",
        "from tensorflow.python.keras import models \n",
        "from tensorflow.python.keras import losses\n",
        "from tensorflow.python.keras import layers\n",
        "from tensorflow.python.keras import backend as K\n",
        "tf.__version__\n",
        "tf.enable_eager_execution()\n",
        "print(\"Eager execution: {}\".format(tf.executing_eagerly()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xE4Yt8nArTeR",
        "colab_type": "text"
      },
      "source": [
        "## 입력 사진 시각화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-b9WcWqy4JWu",
        "colab": {}
      },
      "source": [
        "# Set up some global values here\n",
        "content_path = '/tmp/nst/gwanghwamun.jpg?raw=1'\n",
        "style_path = '/tmp/nst/leejungseob_white_ox.jpg?raw=1'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TLljcwv5qZs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_img(path_to_img):\n",
        "  max_dim = 512\n",
        "  img = Image.open(path_to_img)\n",
        "  long = max(img.size)\n",
        "  scale = max_dim/long\n",
        "  img = img.resize((round(img.size[0]*scale), round(img.size[1]*scale)), Image.ANTIALIAS)\n",
        "  \n",
        "  img = kp_image.img_to_array(img)\n",
        "  \n",
        "  # We need to broadcast the image array such that it has a batch dimension \n",
        "  img = np.expand_dims(img, axis=0)\n",
        "  return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vupl0CI18aAG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def imshow(img, title=None):\n",
        "  # Remove the batch dimension\n",
        "  out = np.squeeze(img, axis=0)\n",
        "  # Normalize for display \n",
        "  out = out.astype('uint8')\n",
        "  plt.imshow(out)\n",
        "  if title is not None:\n",
        "    plt.title(title)\n",
        "  plt.imshow(out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yAlRzJZrWM3",
        "colab_type": "text"
      },
      "source": [
        "컨턴츠 사진과 스타일 사진 확인하기.  \n",
        "우리가 원하는 결과는 컨텐츠 사진을 스타일 사진의 스타일로 합성하는 것 입니다 !"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UWQmeEaiKkP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "\n",
        "content = load_img(content_path).astype('uint8')\n",
        "style = load_img(style_path).astype('uint8')\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "imshow(content, 'Content Image')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "imshow(style, 'Style Image')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qMVNvEsK-_D",
        "colab_type": "text"
      },
      "source": [
        "## 기본적인 데이터 가공\n",
        "### 데이터 전처리 & 후처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGwmTwJNmv2a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_and_process_img(path_to_img):\n",
        "  img = load_img(path_to_img)\n",
        "  img = tf.keras.applications.vgg19.preprocess_input(img)\n",
        "  return img\n",
        "\n",
        "def deprocess_img(processed_img):\n",
        "  x = processed_img.copy()\n",
        "  if len(x.shape) == 4:\n",
        "    x = np.squeeze(x, 0)\n",
        "  assert len(x.shape) == 3, (\"Input to deprocess image must be an image of \"\n",
        "                             \"dimension [1, height, width, channel] or [height, width, channel]\")\n",
        "  if len(x.shape) != 3:\n",
        "    raise ValueError(\"Invalid input to deprocessing image\")\n",
        "  \n",
        "  # perform the inverse of the preprocessiing step\n",
        "  x[:, :, 0] += 103.939\n",
        "  x[:, :, 1] += 116.779\n",
        "  x[:, :, 2] += 123.68\n",
        "  x = x[:, :, ::-1]\n",
        "\n",
        "  x = np.clip(x, 0, 255).astype('uint8')\n",
        "  return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEwZ7FlwrjoZ",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### 사진에서 컨텐츠와 스타일 얻는 방법\n",
        "우리는 사진에서 \"컨텐츠\"와 \"스타일\"을 얻기위해서 딥러닝 모델을 사용할 것 입니다. 우리가 사용할 딥러닝 모델은 여러층으로 이루어져 있는데, 뒤쪽에 위치한 깊은 층일 수록 입력한 사진의 고차원 적인 특징이 추출되고, 앞쪽의 앝은층 일수록 단순한 특징이 추출되는 특성이 있습니다. 이 튜토리얼에서 사용할 딥러닝 모델의 이름은 VGG19 입니다. 원래는 사진 분류기에 사용하기 위해 학습 되었지만 입력된 사진의 \"컨텐츠\"와 \"스타일\"을 추출 할 때도 사용 할 수 있습니다.\n",
        "\n",
        "#### 사진 분류기용 신경망으로 \"컨텐츠\"와 \"스타일\"을 추출 ?\n",
        "어떻게 사진 분류기용 딥러닝 모델을 사용하여 \"컨텐츠\" 와 \"스타일\"을 추출 하는지 궁금하신가요? 우선, 우리가 사용하는 사진 분류기용 딥러닝 모델이 어떻게 동작하는지 설명해야 합니다. 사진 분류기에서 사용되는 딥러닝 모델은 사진을 픽셀 단위로 입력 받아 딥러닝 내부적인 표현 방식으로 변환하여 입력 받은 사진에 존재하는 복잡한 특징을 자체적으로 이해합니다. 특정 사물의 사진들에 공통적으로 존재하는 특징 찾는다면, 이 특징들을 사용하여 사진 분류기로 동작 시킬 수 있습니다. 예를들어, 강아지 사진에만 존재하는 특징을 찾고, 고양이 사진에만 존재하는 특징을 찾는다면 강아지 사진과 고양이 사진을 분류할 수 있는 사진 분류기를 만들 수 있겠죠 ! 이게 바로 딥러닝 기술의 마법 같은 능력입니다. 딥러닝을 사용하여 사진에 존재하는 특징을 추출 하고 이 특징들을 사진 분류기에 사용하는 것 입니다. 그럼 Style Transfer는 어떻게 동작할까요 ? 사진의 \"컨텐츠\"와 \"스타일\" 또한 사진의 특징 중 하나 입니다. 다만,  Style Transfer에서는 사진을 분류하는데 사용하지 않고 추출한 두 특징을 하나의 사진으로 합성하여 새로운 사진을 만들어 내는 것 입니다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jt3i3RRrJiOX",
        "colab_type": "text"
      },
      "source": [
        "## 딥러닝 모델 만들기\n",
        "앞서 말쓴드린 듯이 우리는 [VGG19](https://keras.io/applications/#vgg19)를 사용할 것 입니다. 이 모델은 원래 논문에서 제시되었기도 하고 비교적 간단하면서  높은 성능을 보여줍니다. 이 모델을 사용하여 사진의 \"컨텐츠\"와 \"스타일\"을 추출하여 합성된 이미지를 만들 것입니다. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfec6MuMAbPx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Content layer where will pull our feature maps\n",
        "content_layers = ['block5_conv2'] \n",
        "\n",
        "# Style layer we are interested in\n",
        "style_layers = ['block1_conv1',\n",
        "                'block2_conv1',\n",
        "                'block3_conv1', \n",
        "                'block4_conv1', \n",
        "                'block5_conv1'\n",
        "               ]\n",
        "\n",
        "num_content_layers = len(content_layers)\n",
        "num_style_layers = len(style_layers)\n",
        "\n",
        "def get_model():\n",
        "  \"\"\" Creates our model with access to intermediate layers. \n",
        "  \n",
        "  This function will load the VGG19 model and access the intermediate layers. \n",
        "  These layers will then be used to create a new model that will take input image\n",
        "  and return the outputs from these intermediate layers from the VGG model. \n",
        "  \n",
        "  Returns:\n",
        "    returns a keras model that takes image inputs and outputs the style and \n",
        "      content intermediate layers. \n",
        "  \"\"\"\n",
        "  # Load our model. We load pretrained VGG, trained on imagenet data\n",
        "  vgg = tf.keras.applications.vgg19.VGG19(include_top=False, weights='imagenet')\n",
        "  vgg.trainable = False\n",
        "  # Get output layers corresponding to style and content layers \n",
        "  style_outputs = [vgg.get_layer(name).output for name in style_layers]\n",
        "  content_outputs = [vgg.get_layer(name).output for name in content_layers]\n",
        "  model_outputs = style_outputs + content_outputs\n",
        "  # Build model \n",
        "  return models.Model(vgg.input, model_outputs)\n",
        "\n",
        "def get_feature_representations(model, content_path, style_path):\n",
        "  \"\"\"Helper function to compute our content and style feature representations.\n",
        "\n",
        "  This function will simply load and preprocess both the content and style \n",
        "  images from their path. Then it will feed them through the network to obtain\n",
        "  the outputs of the intermediate layers. \n",
        "  \n",
        "  Arguments:\n",
        "    model: The model that we are using.\n",
        "    content_path: The path to the content image.\n",
        "    style_path: The path to the style image\n",
        "    \n",
        "  Returns:\n",
        "    returns the style features and the content features. \n",
        "  \"\"\"\n",
        "  # Load our images in \n",
        "  content_image = load_and_process_img(content_path)\n",
        "  style_image = load_and_process_img(style_path)\n",
        "  \n",
        "  # batch compute content and style features\n",
        "  style_outputs = model(style_image)\n",
        "  content_outputs = model(content_image)\n",
        "  \n",
        "  \n",
        "  # Get the style and content feature representations from our model  \n",
        "  style_features = [style_layer[0] for style_layer in style_outputs[:num_style_layers]]\n",
        "  content_features = [content_layer[0] for content_layer in content_outputs[num_style_layers:]]\n",
        "  return style_features, content_features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kl6eFGa7-OtV",
        "colab_type": "text"
      },
      "source": [
        "방금 우리는 위 소스코드를 실행하여 학습이 완료된 사진분류기용 딥러닝 모델을 로딩했습니다. 그리고, 우리가 사용할 \"컨텐츠\"와 \"스타일\" 특징이 저장되어 있는 층을 지정하고 특징 추출에 사용할 함수를 정의하였습니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ezVR67gTt-FW"
      },
      "source": [
        "## Loss 함수 와 경사 하강법\n",
        "이 글을 읽는 초심자들에게 Loss함수, 경사하강법과 역전파 등은 익숙한 개념이 아닐 수 있습니다. 이들은 딥러닝 모델을 학습시키기 위해 필수 적인 아주 중요한 요소입니다. 다만, 이 내용은 수학적 배경이 필요하기 때문에 이 튜토리얼에서는 제외 하였습니다. 이 튜토리얼을 실행하기위해 당장 이해할 필요는 없습니다. 자세한 내용이 궁금하신 분들은 튜토리얼 초반에 언급한 자료를 확인해 주세요.   \n",
        "아래의 코드를 실행하면  Loss 함수 와 경사하강에 관련된 필요한 파이썬 함수들이 정의 됩니다. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2mf7JwRMkCd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_content_loss(base_content, target):\n",
        "  return tf.reduce_mean(tf.square(base_content - target))\n",
        "\n",
        "def gram_matrix(input_tensor):\n",
        "  # We make the image channels first \n",
        "  channels = int(input_tensor.shape[-1])\n",
        "  a = tf.reshape(input_tensor, [-1, channels])\n",
        "  n = tf.shape(a)[0]\n",
        "  gram = tf.matmul(a, a, transpose_a=True)\n",
        "  return gram / tf.cast(n, tf.float32)\n",
        "\n",
        "def get_style_loss(base_style, gram_target):\n",
        "  \"\"\"Expects two images of dimension h, w, c\"\"\"\n",
        "  # height, width, num filters of each layer\n",
        "  # We scale the loss at a given layer by the size of the feature map and the number of filters\n",
        "  height, width, channels = base_style.get_shape().as_list()\n",
        "  gram_style = gram_matrix(base_style)\n",
        "  \n",
        "  return tf.reduce_mean(tf.square(gram_style - gram_target))# / (4. * (channels ** 2) * (width * height) ** 2)\n",
        "\n",
        "def compute_loss(model, loss_weights, init_image, gram_style_features, content_features):\n",
        "  \"\"\"This function will compute the loss total loss.\n",
        "  \n",
        "  Arguments:\n",
        "    model: The model that will give us access to the intermediate layers\n",
        "    loss_weights: The weights of each contribution of each loss function. \n",
        "      (style weight, content weight, and total variation weight)\n",
        "    init_image: Our initial base image. This image is what we are updating with \n",
        "      our optimization process. We apply the gradients wrt the loss we are \n",
        "      calculating to this image.\n",
        "    gram_style_features: Precomputed gram matrices corresponding to the \n",
        "      defined style layers of interest.\n",
        "    content_features: Precomputed outputs from defined content layers of \n",
        "      interest.\n",
        "      \n",
        "  Returns:\n",
        "    returns the total loss, style loss, content loss, and total variational loss\n",
        "  \"\"\"\n",
        "  style_weight, content_weight = loss_weights\n",
        "  \n",
        "  # Feed our init image through our model. This will give us the content and \n",
        "  # style representations at our desired layers. Since we're using eager\n",
        "  # our model is callable just like any other function!\n",
        "  model_outputs = model(init_image)\n",
        "  \n",
        "  style_output_features = model_outputs[:num_style_layers]\n",
        "  content_output_features = model_outputs[num_style_layers:]\n",
        "  \n",
        "  style_score = 0\n",
        "  content_score = 0\n",
        "\n",
        "  # Accumulate style losses from all layers\n",
        "  # Here, we equally weight each contribution of each loss layer\n",
        "  weight_per_style_layer = 1.0 / float(num_style_layers)\n",
        "  for target_style, comb_style in zip(gram_style_features, style_output_features):\n",
        "    style_score += weight_per_style_layer * get_style_loss(comb_style[0], target_style)\n",
        "    \n",
        "  # Accumulate content losses from all layers \n",
        "  weight_per_content_layer = 1.0 / float(num_content_layers)\n",
        "  for target_content, comb_content in zip(content_features, content_output_features):\n",
        "    content_score += weight_per_content_layer* get_content_loss(comb_content[0], target_content)\n",
        "  \n",
        "  style_score *= style_weight\n",
        "  content_score *= content_weight\n",
        "\n",
        "  # Get total loss\n",
        "  loss = style_score + content_score \n",
        "  return loss, style_score, content_score\n",
        "\n",
        "def compute_grads(cfg):\n",
        "  with tf.GradientTape() as tape: \n",
        "    all_loss = compute_loss(**cfg)\n",
        "  # Compute gradients wrt input image\n",
        "  total_loss = all_loss[0]\n",
        "  return tape.gradient(total_loss, cfg['init_image']), all_loss\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXIUX6czZABh",
        "colab_type": "text"
      },
      "source": [
        "## 입력 사진에 Style Transfer 적용하기\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9yKu2PLlBIE",
        "colab_type": "text"
      },
      "source": [
        "### 딥러닝 훈련 함수 정의\n",
        "아래의 소스코드를 실행하면 딥러닝 모델을 훈련하기위한 파이썬 함수가 정의 됩니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pj_enNo6tACQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import IPython.display\n",
        "\n",
        "def run_style_transfer(content_path, \n",
        "                       style_path,\n",
        "                       num_iterations=1000,\n",
        "                       content_weight=1e3, \n",
        "                       style_weight=1e-2): \n",
        "  # We don't need to (or want to) train any layers of our model, so we set their\n",
        "  # trainable to false. \n",
        "  model = get_model() \n",
        "  for layer in model.layers:\n",
        "    layer.trainable = False\n",
        "  \n",
        "  # Get the style and content feature representations (from our specified intermediate layers) \n",
        "  style_features, content_features = get_feature_representations(model, content_path, style_path)\n",
        "  gram_style_features = [gram_matrix(style_feature) for style_feature in style_features]\n",
        "  \n",
        "  # Set initial image\n",
        "  init_image = load_and_process_img(content_path)\n",
        "  init_image = tfe.Variable(init_image, dtype=tf.float32)\n",
        "  # Create our optimizer\n",
        "  opt = tf.train.AdamOptimizer(learning_rate=5, beta1=0.99, epsilon=1e-1)\n",
        "\n",
        "  # For displaying intermediate images \n",
        "  iter_count = 1\n",
        "  \n",
        "  # Store our best result\n",
        "  best_loss, best_img = float('inf'), None\n",
        "  \n",
        "  # Create a nice config \n",
        "  loss_weights = (style_weight, content_weight)\n",
        "  cfg = {\n",
        "      'model': model,\n",
        "      'loss_weights': loss_weights,\n",
        "      'init_image': init_image,\n",
        "      'gram_style_features': gram_style_features,\n",
        "      'content_features': content_features\n",
        "  }\n",
        "    \n",
        "  # For displaying\n",
        "  num_rows = 2\n",
        "  num_cols = 5\n",
        "  display_interval = num_iterations/(num_rows*num_cols)\n",
        "  start_time = time.time()\n",
        "  global_start = time.time()\n",
        "  \n",
        "  norm_means = np.array([103.939, 116.779, 123.68])\n",
        "  min_vals = -norm_means\n",
        "  max_vals = 255 - norm_means   \n",
        "  \n",
        "  imgs = []\n",
        "  for i in range(num_iterations):\n",
        "    grads, all_loss = compute_grads(cfg)\n",
        "    loss, style_score, content_score = all_loss\n",
        "    opt.apply_gradients([(grads, init_image)])\n",
        "    clipped = tf.clip_by_value(init_image, min_vals, max_vals)\n",
        "    init_image.assign(clipped)\n",
        "    end_time = time.time() \n",
        "    \n",
        "    if loss < best_loss:\n",
        "      # Update best loss and best image from total loss. \n",
        "      best_loss = loss\n",
        "      best_img = deprocess_img(init_image.numpy())\n",
        "\n",
        "    if i % display_interval== 0:\n",
        "      start_time = time.time()\n",
        "      \n",
        "      # Use the .numpy() method to get the concrete numpy array\n",
        "      plot_img = init_image.numpy()\n",
        "      plot_img = deprocess_img(plot_img)\n",
        "      imgs.append(plot_img)\n",
        "      IPython.display.clear_output(wait=True)\n",
        "      IPython.display.display_png(Image.fromarray(plot_img))\n",
        "      print('Iteration: {}'.format(i))        \n",
        "      print('Total loss: {:.4e}, ' \n",
        "            'style loss: {:.4e}, '\n",
        "            'content loss: {:.4e}, '\n",
        "            'time: {:.4f}s'.format(loss, style_score, content_score, time.time() - start_time))\n",
        "  print('Total time: {:.4f}s'.format(time.time() - global_start))\n",
        "  IPython.display.clear_output(wait=True)\n",
        "  plt.figure(figsize=(14,4))\n",
        "  for i,img in enumerate(imgs):\n",
        "      plt.subplot(num_rows,num_cols,i+1)\n",
        "      plt.imshow(img)\n",
        "      plt.xticks([])\n",
        "      plt.yticks([])\n",
        "      \n",
        "  return best_img, best_loss "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxJPG_GLUFT9",
        "colab_type": "text"
      },
      "source": [
        "### 딥러닝 훈련 함수 실행\n",
        "아래의 소스코드를 실행하면 딥러닝 모델의 훈련이 시작 됩니다. 약 10정도 소요됩니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSVMx4burydi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best, best_loss = run_style_transfer(content_path, \n",
        "                                     style_path, num_iterations=1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fegq87PUnCl",
        "colab_type": "text"
      },
      "source": [
        "#### 결과 확인하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzJTObpsO3TZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Image.fromarray(best)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwiZfCW0AZwt",
        "colab_type": "text"
      },
      "source": [
        "## 결과물 확인하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqTQN1PjulV9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_results(best_img, content_path, style_path, show_large_final=True):\n",
        "  plt.figure(figsize=(10, 5))\n",
        "  content = load_img(content_path) \n",
        "  style = load_img(style_path)\n",
        "\n",
        "  plt.subplot(1, 2, 1)\n",
        "  imshow(content, 'Content Image')\n",
        "\n",
        "  plt.subplot(1, 2, 2)\n",
        "  imshow(style, 'Style Image')\n",
        "\n",
        "  if show_large_final: \n",
        "    plt.figure(figsize=(10, 10))\n",
        "\n",
        "    plt.imshow(best_img)\n",
        "    plt.title('Output Image')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6d6O50Yvs6a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_results(best, content_path, style_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyGMmWh2Pss8",
        "colab_type": "text"
      },
      "source": [
        "## 다른 사진 변환해 보기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2TePU39k9lb",
        "colab_type": "text"
      },
      "source": [
        "### 반고흐 - 별이 빛나는 밤 + 독일 도시 (튀빙겐)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ES9dC6ZyJBD2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_starry_night, best_loss = run_style_transfer('/tmp/nst/Tuebingen_Neckarfront.jpg',\n",
        "                                                  '/tmp/nst/1024px-Van_Gogh_-_Starry_Night_-_Google_Art_Project.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8w8WLkKvzXu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_results(best_starry_night, '/tmp/nst/Tuebingen_Neckarfront.jpg',\n",
        "             '/tmp/nst/1024px-Van_Gogh_-_Starry_Night_-_Google_Art_Project.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcXwvViek4Br",
        "colab_type": "text"
      },
      "source": [
        "### 창조의 기둥 +  독일 도시 (튀빙겐)\n",
        "창조의 기둥이란 허블 우주망원경이 지구로부터 약 7,000 광년 떨어진 독수리 성운의 성간가스와 성간먼지의 덩어리를 촬영한 사진"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJ3u2U-gGmgP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_poc_tubingen, best_loss = run_style_transfer('/tmp/nst/Tuebingen_Neckarfront.jpg', \n",
        "                                                  '/tmp/nst/Pillars_of_creation_2014_HST_WFC3-UVIS_full-res_denoised.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQUq3KxpGv2O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_results(best_poc_tubingen, \n",
        "             '/tmp/nst/Tuebingen_Neckarfront.jpg',\n",
        "             '/tmp/nst/Pillars_of_creation_2014_HST_WFC3-UVIS_full-res_denoised.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTZdTOdW3s8H",
        "colab_type": "text"
      },
      "source": [
        "### 구성VII + 독일 도시 (튀빙겐)\n",
        "구성VII: 바실리 칸딘스키의 그림"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bt9mbQfl7exl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_kandinsky_tubingen, best_loss = run_style_transfer('/tmp/nst/Tuebingen_Neckarfront.jpg', \n",
        "                                                  '/tmp/nst/Vassily_Kandinsky,_1913_-_Composition_7.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qnz8HeXSXg6P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_results(best_kandinsky_tubingen, \n",
        "             '/tmp/nst/Tuebingen_Neckarfront.jpg',\n",
        "             '/tmp/nst/Vassily_Kandinsky,_1913_-_Composition_7.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cg68lW2A3s8N",
        "colab_type": "text"
      },
      "source": [
        "### 창조의 기둥 + 바다 거북\n",
        "창조의 기둥이란 허블 우주망원경이 지구로부터 약 7,000 광년 떨어진 독수리 성운의 성간가스와 성간먼지의 덩어리를 촬영한 사진\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dl0DUot_bFST",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_poc_turtle, best_loss = run_style_transfer('/tmp/nst/Green_Sea_Turtle_grazing_seagrass.jpg', \n",
        "                                                  '/tmp/nst/Pillars_of_creation_2014_HST_WFC3-UVIS_full-res_denoised.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzJfE0I1bQn8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_results(best_poc_turtle, \n",
        "             '/tmp/nst/Green_Sea_Turtle_grazing_seagrass.jpg',\n",
        "             '/tmp/nst/Pillars_of_creation_2014_HST_WFC3-UVIS_full-res_denoised.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWPyDfWjZviq",
        "colab_type": "text"
      },
      "source": [
        "#### 사진 직접 올려보기 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYT4c9BZZvBl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "my_style_image = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHrH2vcwaLrd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_contents_image = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeVneT_jbYn2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(list(my_contents_image.keys())[0], list(my_style_image.keys())[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypdiHyHVbHq4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_image, best_loss = run_style_transfer(list(my_contents_image.keys())[0], list(my_style_image.keys())[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gBG9MZxbDRo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_results(best_image, list(my_contents_image.keys())[0], list(my_style_image.keys())[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-y02GWonqnD",
        "colab_type": "text"
      },
      "source": [
        "#### 사진 정보 \n",
        "\n",
        "**[Image of Tuebingen](https://commons.wikimedia.org/wiki/File:Tuebingen_Neckarfront.jpg)** \n",
        "Photo By: Andreas Praefcke [GFDL (http://www.gnu.org/copyleft/fdl.html) or CC BY 3.0  (https://creativecommons.org/licenses/by/3.0)], from Wikimedia Commons\n",
        "\n",
        "**[Image of Green Sea Turtle](https://commons.wikimedia.org/wiki/File:Green_Sea_Turtle_grazing_seagrass.jpg)**\n",
        "By P.Lindgren [CC BY-SA 3.0 (https://creativecommons.org/licenses/by-sa/3.0)], from Wikimedia Commons\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8l1UTFZVZtcu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}